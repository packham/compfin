{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b> \n",
    "    <font size=\"7\">\n",
    "        Computational Finance and FinTech <br><br>\n",
    "        M.Sc. International Finance\n",
    "    </font>\n",
    "</b>\n",
    "<br><br>\n",
    "<img src=\"pics/HWR.png\" width=400px>\n",
    "<br><br>\n",
    "<b>\n",
    "    <font size=\"5\"> \n",
    "        Prof. Dr. Natalie Packham <br>\n",
    "        Berlin School of Economics and Law <br>\n",
    "        Summer Term 2025\n",
    "    </font>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Model-validation-and-measures-of-fit\" data-toc-modified-id=\"Model-validation-and-measures-of-fit-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Model validation and measures of fit</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mean-square-error-and-overfitting\" data-toc-modified-id=\"Mean-square-error-and-overfitting-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Mean-square error and overfitting</a></span></li><li><span><a href=\"#The-classification-setting\" data-toc-modified-id=\"The-classification-setting-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>The classification setting</a></span></li><li><span><a href=\"#Choosing-the-optimal-model\" data-toc-modified-id=\"Choosing-the-optimal-model-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Choosing the optimal model</a></span></li><li><span><a href=\"#Cross-validation\" data-toc-modified-id=\"Cross-validation-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>Cross-validation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model validation and measures of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"pics/traditional_v_ML.png\" width=600px>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* In Data Science, there is no one single statistical method that performs _best_ across all data sets. \n",
    "* It is an important -- and at times difficult -- task to select the appropriate method or model for a given data set. \n",
    "* We therefore study a number of measures to assess the quality of fit, which in turn allows to compare methods and models. \n",
    "* For a more in-depth treatment, see Chapters 2.2, 5.1 and 6.1.3 of\n",
    "\n",
    "  James, Witten, Hastie, Tibshirani: An Introduction to Statistical Learning. Springer, 2013. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean-square error and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A commonly used measure for assessing how well predictions match observed data is the __mean squared error (MSE)__, which you know e.g. from Ordinary Least Squares (OLS) in linear regression:\n",
    "\n",
    "  $\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat f(x_i))^2$,\n",
    "\n",
    "  where $\\hat f(x_i)$ is the prediction that the fitted method $\\hat f$ gives for the $i$-th observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training and test MSE\n",
    "\n",
    "* In Linear Regression (a statistics method), the whole data set is used for finding a linear function $\\hat f$ that minimises the MSE. \n",
    "* In Data Science (i.e., statistical learning, machine learning, artificial intelligence), it is common to split the data set into a __training data set__ and a __test data set__. \n",
    "* This reflects that we do not really care how well a method works on the training data, but rather we are interested in the accuracy of the prediction when applying the method to previously unseen data (the test data). \n",
    "* In other words, first we fit the training data $\\{(x_1,y_1), (x_2,y_2), \\ldots, (x_n,y_n)\\}$ to obtain the estimate $\\hat f$, e.g. by minimising the MSE on the training data.\n",
    "* Then we calculate the MSE on the test data, which are data points $\\{(x_0,y_0)\\}$ that were not used to training the method. \n",
    "* We want to choose the method that gives the lowest _test MSE_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Remarks\n",
    "\n",
    "* Sometimes an additional __validation data set__ is added to allow for tuning parameters such as the number of hidden units in a neural network.\n",
    "* In econometrics, instead of the terminology training and test data set, we speak of __in-sample__ and __out-of-sample testing__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training and test MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"pics/JamesEtAl_2.9-crop.png\" width=800px>\n",
    "<div align=\"right\" style=\"font-size:14px\">Source: James et al.: An Introduction to Statistical Learning. Springer, 2013.</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Left:\n",
    "* __Test data__, simulated from $f$ (black smooth line) are shown as black dots.\n",
    "* Estimates of $f$: \n",
    "  - linear regression line (orange)\n",
    "  - smoothing spline I (blue)\n",
    "  - smoothing spline II (green)\n",
    "  \n",
    "Right:\n",
    "* Training MSE (grey)\n",
    "* Test MSE (red)\n",
    "* Flexibility denotes the complexity of the models (e.g. number of parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training and test MSE\n",
    "\n",
    "* The green smoothing spline will have the smallest MSE on the training data set. \n",
    "* It does not perform well, however, when __extrapolating__ to the test data set. \n",
    "* This effect is called __overfitting__. \n",
    "* __Overfitting__ refers to choosing a model that fails to capture the _general_ effects due to a too many _degrees of freedom_.\n",
    "* In other words, a less flexible model performs better on the test data than a more flexible model.\n",
    "* A second example is shown on the next slide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"pics/JamesEtAl_2.10-crop.png\" width=800px>\n",
    "<div align=\"right\" style=\"font-size:14px\">Source: James et al.: An Introduction to Statistical Learning. Springer, 2013.</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The classification setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The measure MSE applies in a regression setting. \n",
    "* In a classification setting, we seek to estimate $f$ on the basis of training observations $\\{(x_1,y_1), (x_2,y_2), \\ldots, (x_n,y_n)\\}$, where $y_1, \\ldots, y_n$ are qualitative. \n",
    "* Here, the training __error rate__, which denotes the proportion of mistakes when applying the $\\hat f$ to the training observations is a measure of __accuracy__:\n",
    "\n",
    "  $\\displaystyle\\frac{1}{n} \\sum_{i=1}^n  \\mathbf{1}_{y_i\\not={\\hat y}_i}$,\n",
    "  \n",
    "  where $\\mathbf{1}_A$ is an _indicator function_ taking value $1$ if $A$ is true and $0$ otherwise. \n",
    "* The __test error rate__ is giving as the error rate from applying $\\hat f$ to the test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Bayes classifier\n",
    "\n",
    "* The test error rate is minimised, on average, by the __Bayes classifier__ which assigns each observation to the most likely class given its predictor value, i.e., for an observation $x_k$, and classes $1,\\ldots, j$, it determines the conditional probabilities \n",
    "\n",
    "  $\\mathbb{P}(Y=1|X=x_k), \\ldots, \\mathbb{P}(Y=J|X=x_k)$\n",
    "  \n",
    "  and assigns the class, for which the conditional probability is highest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Bayes classifier\n",
    "\n",
    "<center>\n",
    "<img src=\"pics/JamesEtAl_2.13.png\" width=400px>\n",
    "<div align=\"right\" style=\"font-size:14px\">Source: James et al.: An Introduction to Statistical Learning. Springer, 2013.</div>\n",
    "</center>\n",
    "    \n",
    "* Two-dimensional predictors $X_1$ and $X_2$ and two classes (blue, orange). \n",
    "* Dashed line is the Bayes decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing the optimal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AIC, BIC, Adjusted $R^2$\n",
    "\n",
    "* If the optimal model is chosen based on the training data set, then measures such as MSE or $R^2$ might be misleading. \n",
    "* This is the case for example in a standard regression setting, where we do not differentiate between training and test data sets. \n",
    "* In a regression setting, the $R^2$ will always improve if more independent variables are added. \n",
    "* There are a number of techniques for _adjusting_ the training error according to model size (e.g. different number of independent variables). \n",
    "* These can be used to select amongst models of different size. \n",
    "* Typical measures are: \n",
    "  * Akaike information criterion (AIC)\n",
    "  * Bayesian information criterion (BIC)\n",
    "  * adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AIC, BIC, Adjusted $R^2$\n",
    "\n",
    "* Consider the problem of finding the appropriate predictors (independent variables) in a regression model. \n",
    "* Should you include all variables? Or just a subset of the variables?\n",
    "* Define the _residual sum of squares (RSS)_ as \n",
    "\n",
    "  $\\text{RSS} = \\epsilon_1^2 + \\epsilon_2^2 + \\cdots + \\epsilon_n^2 = (y_1-\\hat\\beta_0 - \\hat\\beta_1 x_1)^2 + (y_2-\\hat\\beta_0 - \\hat\\beta_1 x_2)^2 + \\cdots + (y_n - \\hat\\beta_0 - \\hat\\beta_1 x_n)^2$,\n",
    "              \n",
    "  where $\\hat\\beta_i$ and $x_k$ may be vectors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AIC, BIC, Adjusted $R^2$\n",
    "\n",
    "* Then, the measures above are defined as \n",
    "  * $\\text{AIC} =\\frac{1}{n \\hat{\\sigma}^2} (\\text{RSS} + 2 d {\\hat\\sigma}^2)$;\n",
    "  * $\\text{BIC} = \\frac{1}{n} (\\text{RSS} + \\ln(n) d \\hat\\sigma^2)$;\n",
    "  * $\\text{Adjusted } R^2 = \\displaystyle 1-\\frac{\\text{RSS} / (n-d-1)} {\\text{TSS} / (n-1)}$, with $\\text{TSS} = \\sum (y_i-\\bar y)^2$ the _total sum of squares of the response. \n",
    "  \n",
    "* A further measure, which in OLS regression yields an equivalent model choice as AIC is:\n",
    "  * $C_p = \\frac{1}{n} (\\text{RSS} + 2 d \\hat\\sigma^2)$, with $\\hat\\sigma^2$ an estimate of the error variance and $d$ the dimension of $x_k$. \n",
    "\n",
    "* All measures have in common that they place a penalty on a more complex model, measured by the number of explanatory variables $d$. \n",
    "* Each measure has a theoretical justification; this is beyond the scope of the course, however. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AIC, BIC, Adjusted $R^2$\n",
    "\n",
    "<center>\n",
    "<img src=\"pics/JamesEtAl_6.2.png\" width=700px>\n",
    "<div align=\"right\" style=\"font-size:14px\">Source: James et al.: An Introduction to Statistical Learning. Springer, 2013.</div>\n",
    "</center>\n",
    "    \n",
    "* Estimates of $C_p$ (proportional to AIC), BIC and Adjusted $R^2$ for a data set of credit card defaults with predictors such as age, income, marital status, etc. \n",
    "* A lower $C_p$ and BIC indicate a superior model; likewise a higher Adjusted $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* __Cross validation (CV)__ refers to several methods of building the test and training data sets. \n",
    "* In $k$-fold CV, the data set is randomly divided in $k$ groups or _folds_ of approximately equal size. \n",
    "* In $k$ iterations, each first fold is treated as the test or validation data set, while the $k-1$ other folds are taken as the training data. \n",
    "* In this way, $k$ MSE's of the test error are estimated and the $k$-fold CV estimate is given by \n",
    "\n",
    "  $\\text{CV}_{(k)} = \\displaystyle\\frac{1}{k} \\sum_{i=1}^k \\text{MSE}_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cross-validation\n",
    "\n",
    "<center>\n",
    "<img src=\"pics/JamesEtAl_5.5.png\" width=700px>\n",
    "<div align=\"right\" style=\"font-size:14px\">Source: James et al.: An Introduction to Statistical Learning. Springer, 2013.</div>\n",
    "</center>\n",
    "    \n",
    "* A schematic display of 5-fold CV. \n",
    "* A set of $n$ observations is randomly split into five non-overlapping groups. \n",
    "* Each of these fifths acts as a validation set (shown in beige), and the remainder as a training set (shown in blue). \n",
    "* The test error is estimated by averaging the five resulting MSE estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "latex_metadata": {
   "author": "Prof.\\ Dr.\\ Natalie Packham\\\\ DVFA \\\\ Chartered Financial Data Scientist\\\\ Summer Term 2020",
   "bib": "notebook.bib",
   "title": "Financial Time Series"
  },
  "livereveal": {
   "slideNumber": "c"
  },
  "toc": {
   "base_numbering": "8",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.987px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
